{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "91adbab3-60e5-4d31-87f3-ada899a67692",
    "_uuid": "ac741756-01be-41aa-85d8-3771ba2fa1a3"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "88ad05bc-9857-44d2-94fd-2a0594814ff7",
    "_uuid": "fbc455bb-810a-43f4-8860-e5ddc9b23786"
   },
   "outputs": [],
   "source": [
    "# Импорт библиотек/фукнций из библиотек\n",
    "# Уже импортированы numpy - алгебра и pandas - работа с csv файлами, табличками\n",
    "import matplotlib.pyplot as plt #билиотека, строить графики\n",
    "from sklearn.preprocessing import StandardScaler #Стандартизация характеристик\n",
    "from sklearn.preprocessing import MinMaxScaler #Стандартизация характеристик\n",
    "from sklearn.model_selection import KFold #Функция из библиотеки sklearn для разделения выборки для кросс-валидации\n",
    "from sklearn.linear_model import SGDRegressor #Функция потерь для анализа одной выборки\n",
    "from sklearn.metrics import mean_squared_error #MSE metrics для усреднения оценок кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eebb914b-1522-4df0-aefd-e74907f4598d",
    "_uuid": "713aac0c-74b7-4dce-bdbb-db894c51f206"
   },
   "outputs": [],
   "source": [
    "# Настройка изображения табличек\n",
    "pd.options.display.max_columns = 200 #pd - Библиотека pandas для табличек\n",
    "pd.options.display.max_rows = 100 # ПОЧЕМУ-ТО ТАК НЕ ПОЛУЧАЕТСЯ ВЫВЕСТИ 100 СТРОК :С"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение документов. Такой тип данных называется dataframe, читается с помощью библиотеки pandas\n",
    "# Мы присваиваем переменной результат прочтения документа?\n",
    "train=pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\") \n",
    "test=pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\n",
    "sample_submission=pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10) # чтобы вывести 10 строк, почему-то так работает. Можно просто написать train и будет работать. Почему не нужно писать print()?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0158b6ef-7190-4995-9225-aa8357363228",
    "_uuid": "8e279f09-e852-4bf0-b2ca-746b0706b1be"
   },
   "outputs": [],
   "source": [
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cc548ff3-0887-4b71-9e65-cb5bb8678b35",
    "_uuid": "2bd71d25-9502-48ef-899c-ae59b2a3267d"
   },
   "outputs": [],
   "source": [
    "#Cтандартизация данных (и тренировочных и тестовых) от -1 до 1 (среднее значение 0, дисперсия 1)\n",
    "#mean = train.mean(axis=0)\n",
    "#std = train.std(axis=0)\n",
    "#Вычитаем среднее значение, делим на стандартное отклонение\n",
    "#train -= mean\n",
    "#train /= std\n",
    "#Это не работает. Может из-за того, что в train есть столбцы с буквами и из-за этого нужно изменять по столбцу, а не всю таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "89fd341a-b44f-474b-a5e7-79cc724aa3c3",
    "_uuid": "3113cfeb-8bca-4147-8518-6d2b684c9551"
   },
   "outputs": [],
   "source": [
    "features=[\"GarageArea\", \"MasVnrArea\", \"GrLivArea\", \"YearRemodAdd\", \"GarageYrBlt\", \"YrSold\", \"MoSold\", \"SalePrice\"]\n",
    "#Обязательно ли создавать лист с csv файлами? Нельзя их сразу вытаскивать из таблицы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d5b47860-c27c-4279-bf04-c768c5037d37",
    "_uuid": "2d04fca2-6104-4e09-8120-3b1b52a135d8"
   },
   "outputs": [],
   "source": [
    "#Строим гистограммы для признаков, которые интересны, которые хотим использовать\n",
    "plt.hist( train[\"GarageArea\"], bins = 100)\n",
    "plt.title (\"GarageArea\")\n",
    "plt.show()\n",
    "plt.hist( train[\"MasVnrArea\"], bins = 100)\n",
    "plt.title(\"MasVnrArea\")\n",
    "plt.show()\n",
    "plt.hist( train[\"GrLivArea\"], bins = 100)\n",
    "plt.title (\"GrLivArea\")\n",
    "plt.show()\n",
    "plt.hist( train[\"YearRemodAdd\"], bins = 100)\n",
    "plt.title(\"YearRemodAdd\")\n",
    "plt.show()\n",
    "plt.hist( train[\"GarageYrBlt\"], bins = 100)\n",
    "plt.title(\"GarageYrBlt\")\n",
    "plt.show()\n",
    "plt.hist( train[\"MoSold\"], bins = 100)\n",
    "plt.title (\"MoSold\")\n",
    "plt.show()\n",
    "plt.hist( train[\"YrSold\"], bins = 100)\n",
    "plt.title(\"YrSold\")\n",
    "plt.show()\n",
    "plt.hist( train[\"LotArea\"], bins = 100)\n",
    "plt.title(\"LotArea\")\n",
    "plt.show()\n",
    "plt.hist( train[\"YearBuilt\"], bins = 100)\n",
    "plt.title(\"YearBuilt\")\n",
    "plt.show()\n",
    "#Какое-то черное окно. Не понимаю, почему. Но вроде все остальное ок при этом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d5192cc8-8dd4-4e22-b7ea-4b7afc402131",
    "_uuid": "e82f70ee-6547-4882-9077-4b25f363ffc4"
   },
   "outputs": [],
   "source": [
    "#np.corrcoef(\"GarageArea\",\"Sale Price\")\n",
    "#Почему не работает???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "480d659f-6c9a-493b-90cb-3195ac8fba6d",
    "_uuid": "37ebeccc-46cd-4d0a-9fdb-85725a742b5d"
   },
   "outputs": [],
   "source": [
    "#Визуализируем корреляцию цены с интересующими характеристиками\n",
    "plt.scatter( np.log1p(train [\"GarageArea\"]), np.log1p(train ['SalePrice']), s = 1 )\n",
    "plt.title('Sale Price|GarageArea')\n",
    "plt.show()\n",
    "plt.scatter( np.log1p(train [\"MasVnrArea\"]), np.log1p(train ['SalePrice']), s = 1 )\n",
    "plt.title('Sale Price|MasVnrArea')\n",
    "plt.show()\n",
    "plt.scatter( np.log1p(train [\"GrLivArea\"]), np.log1p(train ['SalePrice']), s = 1 )\n",
    "plt.title('Sale Price|GrLivArea')\n",
    "plt.show()\n",
    "plt.scatter( np.log1p(train [\"YearRemodAdd\"]), np.log1p(train ['SalePrice']), s = 1 )\n",
    "plt.title('Sale Price|YearRemodAdd')\n",
    "plt.show()\n",
    "plt.scatter( np.log1p(train [\"GarageYrBlt\"]), np.log1p(train ['SalePrice']), s = 1 )\n",
    "plt.title('Sale Price|GarageYrBlt')\n",
    "plt.show()\n",
    "plt.scatter( np.log1p(train [\"MoSold\"]), np.log1p(train ['SalePrice']), s = 1 )\n",
    "plt.title('Sale Price|MoSold')\n",
    "plt.show()\n",
    "plt.scatter( np.log1p(train [\"YrSold\"]), np.log1p(train ['SalePrice']), s = 1 )\n",
    "plt.title('Sale Price|YrSold')\n",
    "plt.show()\n",
    "plt.scatter( np.log1p(train [\"LotArea\"]), np.log1p(train ['SalePrice']), s = 1 )\n",
    "plt.title('LotArea|YrSold')\n",
    "plt.show()\n",
    "plt.scatter( np.log1p(train [\"YearBuilt\"]), np.log1p(train ['SalePrice']), s = 1 )\n",
    "plt.title('YearBuilt|YrSold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ffa746e8-16a5-4659-9806-f3e65a9ac805",
    "_uuid": "b50a699b-b2af-4a54-aca6-fe6eee6b1aef"
   },
   "outputs": [],
   "source": [
    "#Выбираем характеристики, коррелирующие со стоимостью домов. Есть признаки, хорошо коррелирующие, но не на всем промежутке. Что с ними можно сделать? Можно ли отбросить части значений, где они плохо предсказывают y? (если признак \"площадь гаража\" равен 0, например)\n",
    "#Для хорошей линейной регрессии нужно нормальное распределение остатков, гомоскедатичность. Если мы предсказываем по нескольким независимым параметрам, то они должны плохо коррелировать между собой.\n",
    "#Выбираю GarageArea, MasVnrArea, GrLivArea, YearRemodAdd, GarageYrBlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"SalePriceLog\"] = np.log1p(train[\"SalePrice\"])\n",
    "#Стандартизуем данные как на занятии показали и в тренировочном и в тестовых наборах\n",
    "#Цель - уменьшить диапазон чисел и привести распределение +- к нормальному\n",
    "#Можно использовать Z-стандартизацию или зажимать значения в отрезке или логнормальное распределение использовать\n",
    "#Как понять, что использовать?\n",
    "#Я решила по гистограммам посмотреть и с сильно ассиметричными использовать StandardScaler, а с более менее норм MinMax\n",
    "\n",
    "Lg_scaler =  StandardScaler() #что делаем этой строчкой?\n",
    "test['GarageAreaLog'] = np.log(test['GarageArea'] + 1) #Сначала Логарифмируем, чтобы уменьшить значения. Но зачем прибавляем единицу???\n",
    "train['GarageAreaLog'] = np.log(train['GarageArea'] + 1)#Создаем новый столбец в таблице, значения в столбце будут равняться np.log от столбца (LogArea +1)\n",
    "train['GarageAreaNormalized'] = Lg_scaler.fit_transform(train[['GarageAreaLog']])#Почему в этой строчке fit_transform\n",
    "test['GarageAreaNormalized'] = Lg_scaler.transform(test[['GarageAreaLog']])#а в этой просто transform?\n",
    "#Почему при стандартизации нельзя сделать так же как и  при логарифмировании? Почему в три странные строчки это действие выполняется? \n",
    "\n",
    "test['MasVnrAreaLog'] = np.log(test['MasVnrArea'] + 1)\n",
    "train['MasVnrAreaLog'] = np.log(train['MasVnrArea'] + 1)\n",
    "train['MasVnrAreaNormalized'] = Lg_scaler.fit_transform(train[['GarageAreaLog']])\n",
    "test['MasVnrAreaNormalized'] = Lg_scaler.transform(test[['GarageAreaLog']])\n",
    "\n",
    "#MinMaxScaler`ом зажимаем все значения в интервале от 0 до 1 (точек в таком интервале больше, чем рациональных чисел - поэтому мы так можем сделать?)\n",
    "MMScal =  MinMaxScaler() \n",
    "\n",
    "train['GrLivAreaNormalized'] = MMScal.fit_transform(train[['GrLivArea']])\n",
    "test['GrLivAreaNormalized'] = MMScal.transform(test[['GrLivArea']])\n",
    "\n",
    "train['YearRemodAddNormalized'] = MMScal.fit_transform(train[['YearRemodAdd']])\n",
    "test['YearRemodAddNormalized'] = MMScal.transform(test[['YearRemodAdd']])\n",
    "\n",
    "train['GarageYrBltNormalized'] = MMScal.fit_transform(train[['GarageYrBlt']])\n",
    "test['GarageYrBltNormalized'] = MMScal.transform(test[['GarageYrBlt']])\n",
    "#После этого можно еще раз визуализировать, чтобы понимать, что изменилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3d06ad0e-b7ac-45c3-8b7d-f14acbb356b9",
    "_uuid": "d1f422b6-e0b3-41fc-8e57-e67a12a7e691"
   },
   "outputs": [],
   "source": [
    "model = SGDRegressor() #заключаем функцию в переменную? что это? Такая же строчка как при стандартизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "43ab9c0a-80db-442e-a5ad-b03425b5d676",
    "_uuid": "0f6a443a-39cf-4c02-864e-15911ae671ef"
   },
   "outputs": [],
   "source": [
    "#Это примерный смысл того, что мы будем делать дальше. Но в начале мы проводим кросс-валидацию\n",
    "#model.fit (train [features], train [[\"SalePriceLog\"]] ) #здесь мы и используем весь наш лист features похоже. Видимо мы создавали его как раз для этого. Находим коээффициенты графика, где y - цена, которую мы предсказываем (второй параметр), а х - независимая переменная (первый параметр). Делаем это все на тренировочных данных.\n",
    "#model.predict (train [features]) #Что делает эта команда?\n",
    "#train_prediction = model.predict( X = train[['YearBuiltNormalized', 'LogLotAreaNormalized'] ] ) #Тут мы вводим обозначение функции, которая не знаю что делает\n",
    "#model.intercept_ #коэффициент b0\n",
    "#model.coef_ #коэффициент b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a2d239e4-cc36-4b71-acfd-ca4adbc7a0af",
    "_uuid": "0d38dd9e-d6cb-479a-bf76-51d5393b7901"
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5) #обозначаем функцию, делящую данные на 5 частей\n",
    "kf.get_n_splits(train) #делим данные train на 5 частей\n",
    "\n",
    "mse_list = [] #обозначили пустой лист\n",
    "rmse_list = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)): #не очень поняла строчку\n",
    "    print( \"Fold: \", i)\n",
    "    #далее мы похоже просто вводим переменные x_train y_train и в них находятся независимые переменные и предсказываемая, соответственно, из столбцов таблицы\n",
    "    #Что значит train.loc?\n",
    "    x_train, x_test = train.loc[train_index, ['GarageAreaNormalized']], train.loc[test_index, ['GarageAreaNormalized']]\n",
    "    y_train, y_test = train.loc[train_index, 'SalePriceLog'],train.loc[test_index, 'SalePriceLog']\n",
    "                                 \n",
    "    #Вот на этом месте я могу менять характеристики по которым предсказываю интересующий меня показатель и комбинировать их.\n",
    "    \n",
    "    model.fit (x_train, y_train)\n",
    "    x_test_predictions = model.predict (x_test)\n",
    "    mse = mean_squared_error (y_true = y_test, y_pred = x_test_predictions)#Обозначаем параметры метрики y_true и y_pred\n",
    "    print(i, mse)\n",
    "    mse_list.append(mse)#для каждого кусочка данных рассчитывается mse и добавляется в лист\n",
    "    rmse_list.append(mse)\n",
    "    \n",
    "    plt.scatter(x_test_predictions, y_test, s = 2)\n",
    "    plt.ylabel('true value')\n",
    "    plt.xlabel('predicted value')\n",
    "    plt.plot(y_test, y_test, c='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c768e11f-dd05-4a3a-937d-ff3007d35ee4",
    "_uuid": "72a72353-fccc-4928-9c6a-cd3c97c3ac46"
   },
   "outputs": [],
   "source": [
    "mse_list #выводит значения ошибок, которые на предыдущем шаге туда собрались"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "260e7ec4-1b6e-4976-8c88-bc06d4452227",
    "_uuid": "7e191ccf-d56e-4f27-8fef-2099c1a50158"
   },
   "outputs": [],
   "source": [
    "print (np.mean(mse_list), np.std(mse_list)) #Зачем стандартное отклонение?\n",
    "print (np.mean(rmse_list), np.std(rmse_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train.loc[:, [ 'GarageAreaNormalized']], train.loc[:,  'SalePriceLog']) #зачем двоеточия?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "633bc9b1-321f-4bfc-8091-e837b323ac7c",
    "_uuid": "cc90bc77-648c-49d4-b40c-2555272acd80"
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test.loc[:, ['GarageAreaNormalized']]) #предсказываем SalePrice по GarageAreaLog из тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['SalePrice'] = np.exp(test_predictions)-1 #создаем столбец в dataframe sample_submission\n",
    "sample_submission.to_csv('submission2.csv', index = None) #сохраняем как csv файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fcb1f2af-b629-4421-af3b-06f6d57a87e4",
    "_uuid": "b4e5a650-866d-442a-860e-a8952102c111"
   },
   "outputs": [],
   "source": [
    "sample_submission #Выводит файл, в который мы должны зписать полученные результаты на тестовой выборке"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
